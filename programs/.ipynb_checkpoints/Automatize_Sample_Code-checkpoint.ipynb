{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatization for HIPERMovelets\n",
    "Sample Code\n",
    "\n",
    "**Observations:**\n",
    "- Not yet compatible with windows, only linux shell\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Paths Configurations\n",
    "You can use configured paths if you want to move directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# root     = './../'\n",
    "root     = '/home/tarlis/Research/tarlis'\n",
    "data     = os.path.join(root, 'data')\n",
    "res_path = os.path.join(root, 'results')\n",
    "prg_path = os.path.join(root, 'programs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Run\n",
    "To run HIPERMovelets, import from package `automatize` the script run.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automatize.run import run, k_run, mergeAndMove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the method run to run HIPERMovelets in terminal comand from Python. In this example we use the configurations:\n",
    "- `data_folder`: \n",
    "- `res_path`:\n",
    "- `prefix`:\n",
    "- `method_name`:\n",
    "- `descriptor`:\n",
    "- `ms`:\n",
    "- `Ms`:\n",
    "- `extra`:\n",
    "- `prg_path`:\n",
    "- `print_only`:\n",
    "- `keep_folder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My Configurations:\n",
    "data_folder = os.path.join(data, 'FoursquareNY')\n",
    "prefix      = 'FoursquareNY'\n",
    "method_name = 'Hiper-Log'\n",
    "descriptor  = 'FoursquareNY_specific'\n",
    "\n",
    "# Print run script:\n",
    "run(data_folder, res_path, prefix, method_name, descriptor, 'hiper', ms=-1, Ms=-3, extra='-T 0.5', \n",
    "    prg_path=prg_path, print_only=True, keep_folder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If, for some reason, you want to join again the results of each class to train.csv / test.csv, you can run the subroutine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mergeAndMove(os.path.join(res_path, prefix, method_name), 'MASTERMovelets', prg_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run k-fold experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My Configurations:\n",
    "data_folder = os.path.join(data, 'FoursquareNY')\n",
    "res_path    = os.path.join(root, 'results')\n",
    "prefix      = 'FoursquareNY'\n",
    "method_name = 'Hiper-Log'\n",
    "descriptor  = 'FoursquareNY_specific'\n",
    "k = 5\n",
    "\n",
    "# Print run script:\n",
    "k_run(k, data_folder, res_path, prefix, method_name, descriptor, 'hiper', ms=-1, Ms=-3, extra='-T 0.5', \n",
    "    prg_path=prg_path, print_only=False, keep_folder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To print run scripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "\n",
    "# My Configurations:\n",
    "data_folder = os.path.join(data, 'scalability')\n",
    "res_path    = os.path.join(root, 'results')\n",
    "\n",
    "prefixes    = ['100_trajectories_50_points', '500_trajectories_50_points', \n",
    "              '1000_trajectories_50_points', '2000_trajectories_50_points', \n",
    "              '4000_trajectories_50_points']\n",
    "\n",
    "jar = 'HIPERMovelets'\n",
    "\n",
    "orig_stdout = sys.stdout\n",
    "f = open('Scalability.sh','w')\n",
    "sys.stdout = f\n",
    "print('#!/bin/bash')\n",
    "\n",
    "for j in range(len(prefixes)):\n",
    "    \n",
    "    variation   = 'Vary_Number_Of_Trajectories'\n",
    "    prefix      = prefixes[j]\n",
    "    descriptor  = os.path.join(data_folder, 'descriptors', 'Scalability_1_Dimension')\n",
    "    results_dir = os.path.join(res_path, 'Scalablity', variation)\n",
    "    data_dir    = os.path.join(data_folder, variation)\n",
    "    \n",
    "    run(data_dir, results_dir, prefix, 'Hiper-Log', descriptor, 'hiper', Ms=-3, \\\n",
    "        prg_path=prg_path, print_only=True, java_opts='-Xmx60G', jar_name=jar, n_threads=3)\n",
    "\n",
    "sys.stdout = orig_stdout\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "\n",
    "# My Configurations:\n",
    "k = 5\n",
    "datasets = ['geo_only', 'specific', 'generic', 'poi_only']\n",
    "prefixes = ['brightkite', 'gowalla', 'foursquare_nyc', 'foursquare_global']\n",
    "descriptors = ['Brightkite_Gowalla', 'Brightkite_Gowalla', 'FoursquareNYC', 'FoursquareGlobal']\n",
    "\n",
    "jar = 'SUPERMovelets'\n",
    "methods = [\n",
    "    ['logd', 'SMLD', 'super'],\n",
    "    ['log',  'SML', 'super'],\n",
    "    ['d',    'SMD', 'super'],\n",
    "    ['x',    'SM', 'super'],\n",
    "]\n",
    "extra  = ['-Al true', False, '-Al true', False]\n",
    "Ms     = [-3, -3, False, False]\n",
    "\n",
    "\n",
    "# jar = 'MASTERMovelets'\n",
    "# methods = [\n",
    "#     ['log',  'MML', 'master'],\n",
    "#     ['x',    'MM', 'master'],\n",
    "# ]\n",
    "# extra  = [False, False]\n",
    "# Ms     = [-3, False]\n",
    "\n",
    "for j in range(0, len(methods)):\n",
    "    method = methods[j]\n",
    "    for i in range(0, len(prefixes)):\n",
    "        prefix = prefixes[i]\n",
    "        for dataset in datasets:\n",
    "            if prefix in ['brightkite', 'gowalla'] and dataset is 'generic':\n",
    "                continue\n",
    "            \n",
    "            orig_stdout = sys.stdout\n",
    "            f = open('./scripts/'+method[2]+'/run5-'+method[2]+'_'+method[0]+'-'+prefix+'-'+dataset+'.sh','w')\n",
    "            sys.stdout = f\n",
    "            \n",
    "            print('#!/bin/bash')\n",
    "\n",
    "            descriptor  = os.path.join(data, '5fold', 'descriptors', descriptors[i]+'_'+dataset)\n",
    "            results_dir = os.path.join(res_path, method[2]+'-'+method[0])\n",
    "            data_dir    = os.path.join(data, '5fold', prefix)\n",
    "\n",
    "            k_run(k, data_dir, results_dir, prefix, method[1]+'-'+dataset, descriptor, Ms=Ms[j], extra=extra[j], \\\n",
    "                prg_path=prg_path, print_only=True, java_opts='-Xmx60G', jar_name=jar, n_threads=3)\n",
    "\n",
    "            sys.stdout = orig_stdout\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "\n",
    "# My Configurations:\n",
    "k = 5\n",
    "datasets = ['geo_only', 'specific', 'generic', 'poi_only']\n",
    "prefixes = ['brightkite', 'gowalla', 'foursquare_nyc', 'foursquare_global']\n",
    "descriptors = ['Brightkite_Gowalla', 'Brightkite_Gowalla', 'FoursquareNYC', 'FoursquareGlobal']\n",
    "\n",
    "jar = 'HIPERMovelets'\n",
    "\n",
    "methods = [\n",
    "    ['logp', 'HpL', 'hiper-pvt'],\n",
    "    ['log',  'HL',  'hiper'],\n",
    "    ['p',    'Hp',  'hiper-pvt'],\n",
    "    ['x',    'H',   'hiper'],\n",
    "]\n",
    "Ms     = [-3, -3, False, False]\n",
    "\n",
    "for j in range(0, len(methods)):\n",
    "    method = methods[j]\n",
    "    for i in range(0, len(prefixes)):\n",
    "        prefix = prefixes[i]\n",
    "        for dataset in datasets:\n",
    "            if prefix in ['brightkite', 'gowalla'] and dataset is 'generic':\n",
    "                continue\n",
    "            \n",
    "            orig_stdout = sys.stdout\n",
    "            f = open('./scripts/hiper/run5-hiper_'+method[0]+'-'+prefix+'-'+dataset+'.sh','w')\n",
    "            sys.stdout = f\n",
    "            \n",
    "            print('#!/bin/bash')\n",
    "\n",
    "            descriptor  = os.path.join(data, '5fold', 'descriptors', descriptors[i]+'_'+dataset)\n",
    "            results_dir = os.path.join(res_path, 'hiper-'+method[0])\n",
    "            data_dir    = os.path.join(data, '5fold', prefix)\n",
    "\n",
    "            k_run(k, data_dir, results_dir, prefix, method[1]+'-'+dataset, descriptor, method[2], Ms=Ms[j], \\\n",
    "                prg_path=prg_path, print_only=True, java_opts='-Xmx60G', jar_name=jar, n_threads=3)\n",
    "\n",
    "            sys.stdout = orig_stdout\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Classification\n",
    "To run classifiers for the HIPERMovelets results, import from package `automatize` the script analysis.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automatize.analysis import def_random_seed, ACC4All, ALL3, MLP, RF, SVM, results2df, printLatex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines a random and a seed numbers for classifyers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results = True\n",
    "\n",
    "def_random_seed(random_num=1, seed_num=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "a. To run the classifyers for each folder inside a result path prefix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC4All(res_path, prefix, save_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. To run the classifyers for a especific result forder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL3(res_path, prefix, method_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. To run a specific classifyer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(res_path, prefix, method_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "To load the results into an dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results2df(res_path, prefix)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "To print the dataframe result in a Latex formatted table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printLatex(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pre-processing data\n",
    "To use helpers for data pre-processing, import from package `automatize` the script preprocessing.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automatize.preprocessing import joinTrainAndTest, kfold_trainAndTestSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To join splitted files use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dir_path = os.path.join(data, 'foursquare_global')\n",
    "cols = ['tid','label','lat','lon','day','hour','poi','category','price','rating']\n",
    "\n",
    "df = joinTrainAndTest(dir_path, cols, train_file=\"specific_train.csv\", test_file=\"specific_test.csv\", class_col = 'label')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To k-fold split a dataset into train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "\n",
    "kfold_trainAndTestSplit(dir_path, k, df, random_num=1, class_col='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# By Tarlis Portela (2020)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
